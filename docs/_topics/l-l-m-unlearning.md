---
title: L L M Unlearning
layout: topic
permalink: /l-l-m-unlearning/
---

# L L M Unlearning

<details markdown="1">
<summary><strong>Table of Contents</strong></summary>

<details markdown="1">
<summary>NeurIPS</summary>

  - [2024](#neurips-2024)

</details>

<details markdown="1">
<summary>ICML</summary>

  - [2025](#icml-2025)
  - [2024](#icml-2024)

</details>

<details markdown="1">
<summary>ICLR</summary>

  - [2025](#iclr-2025)

</details>

<details markdown="1">
<summary>KDD</summary>

  - [2025](#kdd-2025)

</details>

<details markdown="1">
<summary>ACL</summary>

  - [2025](#acl-2025)
  - [2024](#acl-2024)

</details>

<details markdown="1">
<summary>EMNLP</summary>

  - [2024](#emnlp-2024)
  - [2023](#emnlp-2023)

</details>

<details markdown="1">
<summary>AAAI</summary>

  - [2025](#aaai-2025)

</details>

<details markdown="1">
<summary>USENIX Security Symposium</summary>

  - [2025](#usenix-security-symposium-2025)

</details>

<details markdown="1">
<summary>COLING</summary>

  - [2025](#coling-2025)

</details>

</details>


---

## NeurIPS <a id="venue-neurips"></a>

<details>

<summary>Expand NeurIPS</summary>

<a id="neurips-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/b1f78dfc9ca0156498241012aec4efa0-Abstract-Datasets_and_Benchmarks_Track.html">Link</a></td>
</tr>
<tr>
<td>Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/171291d8fed723c6dfc76330aa827ff8-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/3e53d82a1113e3d240059a9195668edc-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/10f34ee79b62627b7ebf6279d35ea480-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/649ad92e7067b3553a0f15acac68806d-Abstract-Conference.html">Link</a></td>
</tr>
</tbody></table>

</details>

## ICML <a id="venue-icml"></a>

<details>

<summary>Expand ICML</summary>

<a id="icml-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Adaptive Localization of Knowledge Negation for Continual LLM Unlearning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=tcK4PV3VN4">Link</a></td>
</tr>
<tr>
<td>Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=mGOugCZlAq">Link</a></td>
</tr>
<tr>
<td>Fast Exact Unlearning for In-Context Learning Data for LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=TzNVZEsqTi">Link</a></td>
</tr>
<tr>
<td>GRU: Mitigating the Trade-off between Unlearning and Retention for LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=EAjhGr1Oeo">Link</a></td>
</tr>
<tr>
<td>Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine-Tuning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=x2lm33kdrZ">Link</a></td>
</tr>
<tr>
<td>Tool Unlearning for Tool-Augmented LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=7ez7LqHsP5">Link</a></td>
</tr>
<tr>
<td>Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=zZjLv6F0Ks">Link</a></td>
</tr>
</tbody></table>

<a id="icml-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models.</td>
<td>ICML</td>
<td>2024</td>
<td><a href="https://openreview.net/forum?id=FWlNA3et6X">Link</a></td>
</tr>
</tbody></table>

</details>

## ICLR <a id="venue-iclr"></a>

<details>

<summary>Expand ICLR</summary>

<a id="iclr-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>A Closer Look at Machine Unlearning for Large Language Models.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=Q1MHvGmhyT">Link</a></td>
</tr>
<tr>
<td>A Probabilistic Perspective on Unlearning and Alignment for Large Language Models.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=51WraMid8K">Link</a></td>
</tr>
<tr>
<td>Catastrophic Failure of LLM Unlearning via Quantization.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=lHSeDYamnz">Link</a></td>
</tr>
<tr>
<td>LLM Unlearning via Loss Adjustment with Only Forget Data.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=6ESRicalFE">Link</a></td>
</tr>
<tr>
<td>Rethinking LLM Unlearning Objectives: A Gradient Perspective and Go Beyond.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=huo8MqVH6t">Link</a></td>
</tr>
<tr>
<td>Towards Effective Evaluations and Comparisons for LLM Unlearning Methods.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=wUtCieKuQU">Link</a></td>
</tr>
<tr>
<td>Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=1ExfUpmIW4">Link</a></td>
</tr>
<tr>
<td>Unified Parameter-Efficient Unlearning for LLMs.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=zONMuIVCAT">Link</a></td>
</tr>
<tr>
<td>Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=fMNRYBvcQN">Link</a></td>
</tr>
</tbody></table>

</details>

## KDD <a id="venue-kdd"></a>

<details>

<summary>Expand KDD</summary>

<a id="kdd-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>LLM-Eraser: Optimizing Large Language Model Unlearning through Selective Pruning.</td>
<td>KDD</td>
<td>2025</td>
<td><a href="https://doi.org/10.1145/3690624.3709312">Link</a></td>
</tr>
</tbody></table>

</details>

## ACL <a id="venue-acl"></a>

<details>

<summary>Expand ACL</summary>

<a id="acl-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>A General Framework to Enhance Fine-tuning-based LLM Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.949/">Link</a></td>
</tr>
<tr>
<td>Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1102/">Link</a></td>
</tr>
<tr>
<td>Decoupling Memories, Muting Neurons: Towards Practical Machine Unlearning for Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.719/">Link</a></td>
</tr>
<tr>
<td>Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.305/">Link</a></td>
</tr>
<tr>
<td>From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.535/">Link</a></td>
</tr>
<tr>
<td>MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.375/">Link</a></td>
</tr>
<tr>
<td>Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.295/">Link</a></td>
</tr>
<tr>
<td>Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.1371/">Link</a></td>
</tr>
<tr>
<td>ReLearn: Unlearning via Learning for Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.297/">Link</a></td>
</tr>
<tr>
<td>Rectifying Belief Space via Unlearning to Harness LLMs&apos; Reasoning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1285/">Link</a></td>
</tr>
<tr>
<td>SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.424/">Link</a></td>
</tr>
<tr>
<td>SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.731/">Link</a></td>
</tr>
<tr>
<td>Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1174/">Link</a></td>
</tr>
<tr>
<td>Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1154/">Link</a></td>
</tr>
<tr>
<td>Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.255/">Link</a></td>
</tr>
<tr>
<td>Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.310/">Link</a></td>
</tr>
</tbody></table>

<a id="acl-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-acl.559">Link</a></td>
</tr>
<tr>
<td>Machine Unlearning of Pre-trained Large Language Models.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.acl-long.457">Link</a></td>
</tr>
<tr>
<td>Towards Safer Large Language Models through Machine Unlearning.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-acl.107">Link</a></td>
</tr>
</tbody></table>

</details>

## EMNLP <a id="venue-emnlp"></a>

<details>

<summary>Expand EMNLP</summary>

<a id="emnlp-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Dissecting Fine-Tuning Unlearning in Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.228">Link</a></td>
</tr>
<tr>
<td>EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.67">Link</a></td>
</tr>
<tr>
<td>SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.245">Link</a></td>
</tr>
<tr>
<td>To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.82">Link</a></td>
</tr>
<tr>
<td>Towards Robust Evaluation of Unlearning in LLMs via Data Transformations.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.706">Link</a></td>
</tr>
<tr>
<td>ULMR: Unlearning Large Language Models via Negative Response and Model Parameter Average.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-industry.57">Link</a></td>
</tr>
</tbody></table>

<a id="emnlp-2023"></a>
<h3 class="year-heading">2023</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Unlearn What You Want to Forget: Efficient Unlearning for LLMs.</td>
<td>EMNLP</td>
<td>2023</td>
<td><a href="https://doi.org/10.18653/v1/2023.emnlp-main.738">Link</a></td>
</tr>
</tbody></table>

</details>

## AAAI <a id="venue-aaai"></a>

<details>

<summary>Expand AAAI</summary>

<a id="aaai-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i24.34769">Link</a></td>
</tr>
</tbody></table>

</details>

## USENIX Security Symposium <a id="venue-usenix security symposium"></a>

<details>

<summary>Expand USENIX Security Symposium</summary>

<a id="usenix security symposium-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.</td>
<td>USENIX Security Symposium</td>
<td>2025</td>
<td><a href="https://www.usenix.org/conference/usenixsecurity25/presentation/song-minkyoo">Link</a></td>
</tr>
</tbody></table>

</details>

## COLING <a id="venue-coling"></a>

<details>

<summary>Expand COLING</summary>

<a id="coling-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Alternate Preference Optimization for Unlearning Factual Knowledge in Large Language Models.</td>
<td>COLING</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.coling-main.252/">Link</a></td>
</tr>
<tr>
<td>Unveiling Entity-Level Unlearning for Large Language Models: A Comprehensive Analysis.</td>
<td>COLING</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.coling-main.358/">Link</a></td>
</tr>
</tbody></table>

</details>
