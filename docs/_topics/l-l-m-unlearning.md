---
title: L L M Unlearning
layout: topic
permalink: /l-l-m-unlearning/
---

# L L M Unlearning

<details markdown="1">
<summary><strong>Table of Contents</strong></summary>

<details markdown="1">
<summary>NeurIPS</summary>

  - [2024](#neurips-2024)

</details>

<details markdown="1">
<summary>ICML</summary>

  - [2025](#icml-2025)
  - [2024](#icml-2024)

</details>

<details markdown="1">
<summary>ICLR</summary>

  - [2025](#iclr-2025)

</details>

<details markdown="1">
<summary>KDD</summary>

  - [2025](#kdd-2025)

</details>

<details markdown="1">
<summary>ACL</summary>

  - [2025](#acl-2025)
  - [2024](#acl-2024)
  - [2023](#acl-2023)

</details>

<details markdown="1">
<summary>EMNLP</summary>

  - [2025](#emnlp-2025)
  - [2024](#emnlp-2024)
  - [2023](#emnlp-2023)

</details>

<details markdown="1">
<summary>AAAI</summary>

  - [2025](#aaai-2025)

</details>

<details markdown="1">
<summary>USENIX Security Symposium</summary>

  - [2025](#usenix-security-symposium-2025)

</details>

<details markdown="1">
<summary>COLING</summary>

  - [2025](#coling-2025)

</details>

<details markdown="1">
<summary>CIKM</summary>

  - [2025](#cikm-2025)

</details>

<details markdown="1">
<summary>Expert Syst. Appl.</summary>

  - [2025](#expert-syst-appl-2025)

</details>

<details markdown="1">
<summary>Neural Networks</summary>

  - [2025](#neural-networks-2025)

</details>

<details markdown="1">
<summary>IEEE Trans. Knowl. Data Eng.</summary>

  - [2025](#ieee-trans-knowl-data-eng-2025)

</details>

<details markdown="1">
<summary>Nat. Mac. Intell.</summary>

  - [2025](#nat-mac-intell-2025)

</details>

</details>


---

## NeurIPS <a id="venue-neurips"></a>

<details>

<summary>Expand NeurIPS</summary>

<a id="neurips-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Large Language Model Unlearning via Embedding-Corrupted Prompts.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/d6359156e0e30b1caa116a4306b12688-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>Large Language Model Unlearning.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/be52acf6bccf4a8c0a90fe2f5cfcead3-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/b1f78dfc9ca0156498241012aec4efa0-Abstract-Datasets_and_Benchmarks_Track.html">Link</a></td>
</tr>
<tr>
<td>Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/171291d8fed723c6dfc76330aa827ff8-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/3e53d82a1113e3d240059a9195668edc-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/10f34ee79b62627b7ebf6279d35ea480-Abstract-Conference.html">Link</a></td>
</tr>
<tr>
<td>WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models.</td>
<td>NeurIPS</td>
<td>2024</td>
<td><a href="http://papers.nips.cc/paper_files/paper/2024/hash/649ad92e7067b3553a0f15acac68806d-Abstract-Conference.html">Link</a></td>
</tr>
</tbody></table>

</details>

## ICML <a id="venue-icml"></a>

<details>

<summary>Expand ICML</summary>

<a id="icml-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Adaptive Localization of Knowledge Negation for Continual LLM Unlearning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=tcK4PV3VN4">Link</a></td>
</tr>
<tr>
<td>Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=mGOugCZlAq">Link</a></td>
</tr>
<tr>
<td>Fast Exact Unlearning for In-Context Learning Data for LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=TzNVZEsqTi">Link</a></td>
</tr>
<tr>
<td>GRU: Mitigating the Trade-off between Unlearning and Retention for LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=EAjhGr1Oeo">Link</a></td>
</tr>
<tr>
<td>Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine-Tuning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=x2lm33kdrZ">Link</a></td>
</tr>
<tr>
<td>Tool Unlearning for Tool-Augmented LLMs.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=7ez7LqHsP5">Link</a></td>
</tr>
<tr>
<td>Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=zZjLv6F0Ks">Link</a></td>
</tr>
<tr>
<td>Underestimated Privacy Risks for Minority Populations in Large Language Model Unlearning.</td>
<td>ICML</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=NsU6MKwbis">Link</a></td>
</tr>
</tbody></table>

<a id="icml-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>In-Context Unlearning: Language Models as Few-Shot Unlearners.</td>
<td>ICML</td>
<td>2024</td>
<td><a href="https://openreview.net/forum?id=GKcwle8XC9">Link</a></td>
</tr>
<tr>
<td>To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models.</td>
<td>ICML</td>
<td>2024</td>
<td><a href="https://openreview.net/forum?id=FWlNA3et6X">Link</a></td>
</tr>
</tbody></table>

</details>

## ICLR <a id="venue-iclr"></a>

<details>

<summary>Expand ICLR</summary>

<a id="iclr-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>A Closer Look at Machine Unlearning for Large Language Models.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=Q1MHvGmhyT">Link</a></td>
</tr>
<tr>
<td>A Probabilistic Perspective on Unlearning and Alignment for Large Language Models.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=51WraMid8K">Link</a></td>
</tr>
<tr>
<td>Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=0y3hGn1wOk">Link</a></td>
</tr>
<tr>
<td>Catastrophic Failure of LLM Unlearning via Quantization.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=lHSeDYamnz">Link</a></td>
</tr>
<tr>
<td>LLM Unlearning via Loss Adjustment with Only Forget Data.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=6ESRicalFE">Link</a></td>
</tr>
<tr>
<td>MUSE: Machine Unlearning Six-Way Evaluation for Language Models.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=TArmA033BU">Link</a></td>
</tr>
<tr>
<td>On Large Language Model Continual Unlearning.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=Essg9kb4yx">Link</a></td>
</tr>
<tr>
<td>Rethinking LLM Unlearning Objectives: A Gradient Perspective and Go Beyond.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=huo8MqVH6t">Link</a></td>
</tr>
<tr>
<td>Towards Effective Evaluations and Comparisons for LLM Unlearning Methods.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=wUtCieKuQU">Link</a></td>
</tr>
<tr>
<td>Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=1ExfUpmIW4">Link</a></td>
</tr>
<tr>
<td>Unified Parameter-Efficient Unlearning for LLMs.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=zONMuIVCAT">Link</a></td>
</tr>
<tr>
<td>Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning.</td>
<td>ICLR</td>
<td>2025</td>
<td><a href="https://openreview.net/forum?id=fMNRYBvcQN">Link</a></td>
</tr>
</tbody></table>

</details>

## KDD <a id="venue-kdd"></a>

<details>

<summary>Expand KDD</summary>

<a id="kdd-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>LLM-Eraser: Optimizing Large Language Model Unlearning through Selective Pruning.</td>
<td>KDD</td>
<td>2025</td>
<td><a href="https://doi.org/10.1145/3690624.3709312">Link</a></td>
</tr>
</tbody></table>

</details>

## ACL <a id="venue-acl"></a>

<details>

<summary>Expand ACL</summary>

<a id="acl-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>A General Framework to Enhance Fine-tuning-based LLM Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.949/">Link</a></td>
</tr>
<tr>
<td>Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1276/">Link</a></td>
</tr>
<tr>
<td>Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1102/">Link</a></td>
</tr>
<tr>
<td>Decoupling Memories, Muting Neurons: Towards Practical Machine Unlearning for Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.719/">Link</a></td>
</tr>
<tr>
<td>Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.305/">Link</a></td>
</tr>
<tr>
<td>From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.535/">Link</a></td>
</tr>
<tr>
<td>MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.375/">Link</a></td>
</tr>
<tr>
<td>Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.295/">Link</a></td>
</tr>
<tr>
<td>Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.1371/">Link</a></td>
</tr>
<tr>
<td>REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.763/">Link</a></td>
</tr>
<tr>
<td>ReLearn: Unlearning via Learning for Large Language Models.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.297/">Link</a></td>
</tr>
<tr>
<td>Rectifying Belief Space via Unlearning to Harness LLMs&apos; Reasoning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1285/">Link</a></td>
</tr>
<tr>
<td>SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.acl-long.424/">Link</a></td>
</tr>
<tr>
<td>SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.731/">Link</a></td>
</tr>
<tr>
<td>Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1174/">Link</a></td>
</tr>
<tr>
<td>Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.1154/">Link</a></td>
</tr>
<tr>
<td>Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.255/">Link</a></td>
</tr>
<tr>
<td>Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning.</td>
<td>ACL</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.findings-acl.310/">Link</a></td>
</tr>
</tbody></table>

<a id="acl-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-acl.559">Link</a></td>
</tr>
<tr>
<td>Machine Unlearning of Pre-trained Large Language Models.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.acl-long.457">Link</a></td>
</tr>
<tr>
<td>Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-acl.936">Link</a></td>
</tr>
<tr>
<td>Towards Safer Large Language Models through Machine Unlearning.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-acl.107">Link</a></td>
</tr>
<tr>
<td>Unlearning Traces the Influential Training Data of Language Models.</td>
<td>ACL</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.acl-long.343">Link</a></td>
</tr>
</tbody></table>

<a id="acl-2023"></a>
<h3 class="year-heading">2023</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Knowledge Unlearning for Mitigating Privacy Risks in Language Models.</td>
<td>ACL</td>
<td>2023</td>
<td><a href="https://doi.org/10.18653/v1/2023.acl-long.805">Link</a></td>
</tr>
<tr>
<td>Unlearning Bias in Language Models by Partitioning Gradients.</td>
<td>ACL</td>
<td>2023</td>
<td><a href="https://doi.org/10.18653/v1/2023.findings-acl.375">Link</a></td>
</tr>
</tbody></table>

</details>

## EMNLP <a id="venue-emnlp"></a>

<details>

<summary>Expand EMNLP</summary>

<a id="emnlp-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>A Fully Probabilistic Perspective on Large Language Model Unlearning: Evaluation and Optimization.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.452">Link</a></td>
</tr>
<tr>
<td>Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.1109">Link</a></td>
</tr>
<tr>
<td>Mitigating Biases in Language Models via Bias Unlearning.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.208">Link</a></td>
</tr>
<tr>
<td>OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.183">Link</a></td>
</tr>
<tr>
<td>REVIVING YOUR MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.1641">Link</a></td>
</tr>
<tr>
<td>SEPS: A Separability Measure for Robust Unlearning in LLMs.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.283">Link</a></td>
</tr>
<tr>
<td>SUA: Stealthy Multimodal Large Language Model Unlearning Attack.</td>
<td>EMNLP</td>
<td>2025</td>
<td><a href="https://doi.org/10.18653/v1/2025.emnlp-main.565">Link</a></td>
</tr>
</tbody></table>

<a id="emnlp-2024"></a>
<h3 class="year-heading">2024</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Can Machine Unlearning Reduce Social Bias in Language Models?</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-industry.71">Link</a></td>
</tr>
<tr>
<td>Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.630">Link</a></td>
</tr>
<tr>
<td>Dissecting Fine-Tuning Unlearning in Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.228">Link</a></td>
</tr>
<tr>
<td>EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.67">Link</a></td>
</tr>
<tr>
<td>Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.566">Link</a></td>
</tr>
<tr>
<td>SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-main.245">Link</a></td>
</tr>
<tr>
<td>To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.82">Link</a></td>
</tr>
<tr>
<td>Towards Robust Evaluation of Unlearning in LLMs via Data Transformations.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.706">Link</a></td>
</tr>
<tr>
<td>ULMR: Unlearning Large Language Models via Negative Response and Model Parameter Average.</td>
<td>EMNLP</td>
<td>2024</td>
<td><a href="https://doi.org/10.18653/v1/2024.emnlp-industry.57">Link</a></td>
</tr>
</tbody></table>

<a id="emnlp-2023"></a>
<h3 class="year-heading">2023</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models.</td>
<td>EMNLP</td>
<td>2023</td>
<td><a href="https://doi.org/10.18653/v1/2023.emnlp-main.265">Link</a></td>
</tr>
<tr>
<td>Unlearn What You Want to Forget: Efficient Unlearning for LLMs.</td>
<td>EMNLP</td>
<td>2023</td>
<td><a href="https://doi.org/10.18653/v1/2023.emnlp-main.738">Link</a></td>
</tr>
</tbody></table>

</details>

## AAAI <a id="venue-aaai"></a>

<details>

<summary>Expand AAAI</summary>

<a id="aaai-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i23.34605">Link</a></td>
</tr>
<tr>
<td>Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i19.34218">Link</a></td>
</tr>
<tr>
<td>On Effects of Steering Latent Representation for Large Language Model Unlearning.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i22.34544">Link</a></td>
</tr>
<tr>
<td>Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i1.32068">Link</a></td>
</tr>
<tr>
<td>Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models.</td>
<td>AAAI</td>
<td>2025</td>
<td><a href="https://doi.org/10.1609/aaai.v39i24.34769">Link</a></td>
</tr>
</tbody></table>

</details>

## USENIX Security Symposium <a id="venue-usenix security symposium"></a>

<details>

<summary>Expand USENIX Security Symposium</summary>

<a id="usenix security symposium-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Refusal Is Not an Option: Unlearning Safety Alignment of Large Language Models.</td>
<td>USENIX Security Symposium</td>
<td>2025</td>
<td><a href="https://www.usenix.org/conference/usenixsecurity25/presentation/song-minkyoo">Link</a></td>
</tr>
</tbody></table>

</details>

## COLING <a id="venue-coling"></a>

<details>

<summary>Expand COLING</summary>

<a id="coling-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Alternate Preference Optimization for Unlearning Factual Knowledge in Large Language Models.</td>
<td>COLING</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.coling-main.252/">Link</a></td>
</tr>
<tr>
<td>Unveiling Entity-Level Unlearning for Large Language Models: A Comprehensive Analysis.</td>
<td>COLING</td>
<td>2025</td>
<td><a href="https://aclanthology.org/2025.coling-main.358/">Link</a></td>
</tr>
</tbody></table>

</details>

## CIKM <a id="venue-cikm"></a>

<details>

<summary>Expand CIKM</summary>

<a id="cikm-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Pseudo-Inverse Prefix Tuning for Effective Unlearning in LLMs.</td>
<td>CIKM</td>
<td>2025</td>
<td><a href="https://doi.org/10.1145/3746252.3760939">Link</a></td>
</tr>
</tbody></table>

</details>

## Expert Syst. Appl. <a id="venue-expert syst. appl."></a>

<details>

<summary>Expand Expert Syst. Appl.</summary>

<a id="expert syst. appl.-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Law LLM unlearning via interfere prompt, review output and update parameter: new challenges, method and baseline.</td>
<td>Expert Syst. Appl.</td>
<td>2025</td>
<td><a href="https://doi.org/10.1016/j.eswa.2025.128612">Link</a></td>
</tr>
</tbody></table>

</details>

## Neural Networks <a id="venue-neural networks"></a>

<details>

<summary>Expand Neural Networks</summary>

<a id="neural networks-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>DP2Unlearning: An efficient and guaranteed unlearning framework for LLMs.</td>
<td>Neural Networks</td>
<td>2025</td>
<td><a href="https://doi.org/10.1016/j.neunet.2025.107879">Link</a></td>
</tr>
</tbody></table>

</details>

## IEEE Trans. Knowl. Data Eng. <a id="venue-ieee trans. knowl. data eng."></a>

<details>

<summary>Expand IEEE Trans. Knowl. Data Eng.</summary>

<a id="ieee trans. knowl. data eng.-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Exact and Efficient Unlearning for Large Language Model-Based Recommendation.</td>
<td>IEEE Trans. Knowl. Data Eng.</td>
<td>2025</td>
<td><a href="https://doi.org/10.1109/TKDE.2025.3594687">Link</a></td>
</tr>
</tbody></table>

</details>

## Nat. Mac. Intell. <a id="venue-nat. mac. intell."></a>

<details>

<summary>Expand Nat. Mac. Intell.</summary>

<a id="nat. mac. intell.-2025"></a>
<h3 class="year-heading">2025</h3>
<table class="paper-table">
<colgroup>
<col style="width: 60%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 10%">
</colgroup>
<thead><tr>
<th>Title</th>
<th> Venue</th>
<th> Year </th>
<th>Link</th>
</tr></thead>
<tbody>
<tr>
<td>Rethinking machine unlearning for large language models.</td>
<td>Nat. Mac. Intell.</td>
<td>2025</td>
<td><a href="https://doi.org/10.1038/s42256-025-00985-0">Link</a></td>
</tr>
</tbody></table>

</details>
